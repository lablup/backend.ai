# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2016-2018, Lablup Inc.
# This file is distributed under the same license as the Backend.AI API
# Documentation package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Backend.AI API Documentation 1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-06 03:39+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.1\n"

#: ../../install/install-cuda.rst:2 5bb7e0f45d8f42b6a289813f2918b3a3
msgid ""
"On the clouds, we highly recommend using vendor-provided GPU-optimized "
"instance types (e.g., p2/p3 series on AWS) and GPU-optimized virtual machine "
"images which include ready-to-use CUDA drivers and configurations."
msgstr ""

#: ../../install/install-cuda.rst:4 1372feee4fa54a80820920c5665e50b1
msgid ""
"Since Backend.AI's kernel container images ship all the necessary libraries "
"and 3rd-party computation packages, you may choose the light-weight \"base\" "
"image (e.g., Amazon Deep Learning *Base* AMI) instead of full-featured "
"images (e.g., Amazon Deep Learning Conda AMI)."
msgstr ""

#: ../../install/install-cuda.rst:7 d13205a79135417fa61ff0cc89c8a8f6
msgid "Manually install CUDA at on-premise GPU servers"
msgstr ""

#: ../../install/install-cuda.rst:9 36b2e8cbb8bd4358b926fd7315d9abdd
msgid ""
"Please search for this topic on the Internet, as Linux distributions often "
"provide their own driver packages and optimized method to install CUDA."
msgstr ""

#: ../../install/install-cuda.rst:11 49338fb33ea941f797f1b857023b4d6d
msgid ""
"To download the driver and CUDA toolkit directly from NVIDIA, `visit here "
"<https://developer.nvidia.com/cuda-downloads>`_."
msgstr ""

#: ../../install/install-cuda.rst:14 7544e4c4079d4405a1c708efaf409931
msgid "Let Backend.AI to utilize GPUs"
msgstr ""

#: ../../install/install-cuda.rst:16 c332978c0c5943d6a7389f909ef0ffb4
msgid ""
"If an agent server has properly configured nvidia-docker (ref: [[Install "
"Docker]]) with working host-side drivers and the agent's Docker daemon has "
"GPU-enabled kernel images, there is *nothing* to do special. Backend.AI "
"tracks the GPU capacity just like CPU cores and RAM, and uses that "
"information to schedule and assign GPU-enabled kernels."
msgstr ""
