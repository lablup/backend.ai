[service]
ip = "0.0.0.0"
port = 8080
wsproxy.url = ""

# If you need ssl-enabled server, fill these configurations.
#ssl_enabled = true
#ssl_cert =
#ssl_privkey =

# Set or enable it when using nginx proxy
#force_endpoint_protocol = "https"

# Manually set the static path for site customization.
# (default: the directory where the package ai.backend.web.static is installed)
# TIP: If you clone the backend.ai-webui repository under src/ai/backend/webui,
# this could be set "src/ai/backend/webui/build/rollup" to directly serve
# the compiled result from the source.
#static_path = "/absolute/path/to/static/resources/"

# "webui" mode is for serving "backend.ai-webui" PWA,
# where non-existent URLs are fall-back to "index.html"
# and "config.ini" is generated on the fly.
# "static" mode is for serving the static directory as-is,
# without any fallback or hooks.
mode = "webui"
# Enable signup feature support.
enable_signup = false
# Let anonymous user can request an email with a link to change password.
allow_anonymous_change_password = false
# Allow users to see user's current project resource monitor
allow_project_resource_monitor = false
# Allow users to change signin mode between ID/Password and IAM mode
allow_change_signin_mode = false
# Allow users to use the specific environment image by typing the exact name.
allow_manual_image_name_for_session = false
# Allow users can sign up without confirmation such as token or email confirmation.
allow_signup_without_confirmation = false
# Allow users enqueue the compute session
always_enqueue_compute_session = false
# Debug mode for Web-UI (not Webserver's debug flag)
webui_debug = false
# Enable masking user information
mask_user_info = false
# Comma-separeated list of available SSO vendors: "saml,openid"
# single_sign_on_vendors = "saml"
# Custom name to display at login page instead of just "SAML" or "OpenID"
# sso_realm_name = "Custom Login"
# Enable/disable container commit button and query.
# enable_container_commit = false
# Hide agent information for users.
# hide_agents = true
# URL to download the webui electron app. If blank, https://github.com/lablup/backend.ai-webui/releases/download will be used.
# app_download_url = ""
# Allow users to see the panel downloading the webui app from the summary page.
# allow_app_download_panel = true
# Enable/disable 2-Factor-Authentication (TOTP).
enable_2FA = false
# Force enable 2-Factor-Authentication (TOTP).
force_2FA = false
# Container image to use SSH/SFTP file upload when storage proxy configuration supports independent resource group for file transfer.
# If the appropriate settings are not made, please leave it blank.
# system_SSH_image = ""
# If true, display the amount of usage per directory such as folder capacity, and number of files and directories.
directory_based_usage = false
# If true, display the custom allocation on the session launcher.
# allow_custom_resource_allocation = true
is_directory_size_visible = true
# edu_appname_prefix = "" 
# If false, the model store will be disabled.
# enable_extend_login_session = False
# If false, directory size in folder explorer will show `-`. default value is set to true.
# If true, display the "Sign in with a different account" button on the interactive login page.
# If false, hide the "Sign in with a different account" button from the interactive login page.
enable_interactive_login_account_switch = true
# Default file browser image. If not specified, an arbitrary installed file browser image will be used.
# default_file_browser_image = ""
# Enable/disable reservoir feature.
enable_reservoir = false

[resources]
# Display "Open port to public" checkbox in the app launcher.
# If checked, the app will be accessible by anyone who has network to the URL.
open_port_to_public = false
# Display apps running under TCP protocol in the app launcher.
# Only setting this value to true won't actually enable TCP-based apps to be open successfully.
# AppProxy nodes must be configured to accept TCP traffics properly in order for the TCP apps to work.
allow_non_auth_tcp = false
# Display "Try preferred port" checkbox in the app launcher.
# If checked and enter a specific port number, Backend.AI try to assign the entered port number first for the web service.
allow_preferred_port = false
# Maximum CPU cores allowed per container (int)
max_cpu_cores_per_container = 64
# Maximum memory allowed per container (int)
max_memory_per_container = 64
# Maximum CUDA devices allowed per container (int)
max_cuda_devices_per_container = 16
# Maximum CUDA fGPUs allowed per container (int)
max_cuda_shares_per_container = 16
# Maximum shared memory allowed per container (float)
max_shm_per_container = 2
# Maximum per-file upload size (bytes)
max_file_upload_size = 4294967296


[security]
# Policies to be applied before processing a request in the handler.
# reject_metadata_local_link_policy: If a request comes from the HOST of metadata_local_link, it will be rejected.
# reject_access_for_unsafe_file_policy: If a user requests files related to server security, your request will be denied.
request_policies = ["reject_metadata_local_link_policy", "reject_access_for_unsafe_file_policy"]
# Policies to apply after the handler operation is performed but before delivering the response.
# set_content_type_nosniff_policy: Set the X-Content-Type-Options header to 'nosniff'.
response_policies = ["set_content_type_nosniff_policy"]

[security.csp]
# Content Security Policy (CSP) settings.
# See https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP for more details.
default-src = ["'self'"]
style-src = ["'self'", "'unsafe-inline'"]
font-src = ["'self'", "data:"]
# It is necessary to set up access to storage-proxy and wsproxy in order to upload files from the web.
connect-src = ["'self'", "http://127.0.0.1:6021", "http://127.0.0.1:5050"]
frame-ancestors = ["'none'"]
form-action = ["'self'"]

[environments]
# Comma-separated string
# Image name should contain the repository (registry path and image name) part of the full image URL, excluding the protocol and tag
# e.g. cr.backend.ai/stable/python
# You should pick default_environment in ui section too.
#allowlist = ""
# Show all environment images regardless of installation
show_non_installed_images = false

[plugin]
# Comma-separated string
# Should be same as plugin file in web UI plugin directory.
#page = ""

[pipeline]
# Endpoint to the pipeline service
#endpoint = "http://127.0.0.1:9500"
# Endpoint to the pipeline service's frontend
#frontend-endpoint = "http://127.0.0.1:3000"

[ui]
# Default environment to show on session launcher
# default_environment = 'index.docker.io/lablup/python-tensorflow'
# Default environment to import GitHub repositories / notebooks
# default_import_environment = 'index.docker.io/lablup/python:3.6-ubuntu18.04'
# Comma-separated sidebar menu pages to hide
menu_blocklist = "pipeline"
# Comma-separated sidebar menu pages to disable
#menu_inactivelist = "statistics"
# Enable/disable the Models tab and MODEL usage mode in the Data page
# enable_model_folders = true

[api]
domain = "default"
endpoint = "https://api.backend.ai"
# endpoint = "https://api.backend.ai,https://alt.backend.ai"  # for HA manager endpoints
text = "Backend.AI Cloud"
ssl_verify = true
# Cookie key to be used for token-based login
auth_token_name = 'sToken'

[session]
redis.addr = "localhost:8111"
# redis.db = 0
# redis.password = "mysecret"

# Customizes the settings of the Redis connection object used in the web server.
# redis.redis_helper_config.socket_timeout = 5
# redis.redis_helper_config.socket_connect_timeout = 2
# redis.redis_helper_config.reconnect_poll_timeout = 0.3

max_age = 604800  # 1 week
login_session_extension_sec = 3600 # 1 hr
flush_on_startup = false
# Time to block login when an email consecutively fails to login
login_block_time = 1200  # 20 min (in sec)
# Number of allowed consecutive failed logins. If this user fails
# to login consecutively over this number, login with the account
# is blocked for ``block_time``.
login_allowed_fail_count = 10
# Auto logout when user closes all Backend.AI web UI tab / window
#auto_logout = false
# The maximum allowed number of pre-opened ports. If you set this option to 0, the pre-opened port is disabled.
max_count_for_preopen_ports = 10

[webserver]
# Create a PID file so that daemon webserver could keep track of us.
# If set to an empty string, it does NOT create the PID file.
# pid-file = "./webserver.pid"

# One of: "asyncio", "uvloop"
# This changes the event loop backend.
# uvloop is a fast libuv-based implementation but sometimes has
# compatibility issues.
# event-loop = "uvloop"

# The base directory to put domain sockets for IPC.
# Normally you don't have to change it.
# NOTE: If Docker is installed via Snap (https://snapcraft.io/docker),
#       you must change this to a directory under your *home* directory.
# ipc-base-path = "/tmp/backend.ai/ipc"

[logging]
# One of: "NOTSET", "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
# Set the global logging level.
level = "INFO"

# Multi-choice of: "console", "logstash", "file"
# For each choice, there must be a "logging.<driver>" section
# in this config file as exemplified below.
drivers = ["console", "file"]

[logging.console]
# If set true, use ANSI colors if the console is a terminal.
# If set false, always disable the colored output in console logs.
colored = true

# One of: "simple", "verbose"
format = "verbose"

[logging.file]
# The log file path and filename pattern.
# All messages are wrapped in single-line JSON objects.
# Rotated logs may have additional suffixes.
# For production, "/var/log/backend.ai" is recommended.
path = "./logs"
filename = "webserver.log"

# Set the maximum number of recent container coredumps in the coredump directory.
# Oldest coredumps are deleted if there is more than this number of coredumps.
backup-count = 10

# The log file size to begin rotation.
rotation-size = "10M"

[logging.logstash]
# The endpoint to publish logstash records.
endpoint = { host = "localhost", port = 9300 }

# One of: "zmq.push", "zmq.pub", "tcp", "udp"
protocol = "tcp"

# SSL configs when protocol = "tcp"
ssl-enabled = true
ssl-verify = true

# Specify additional package namespaces to include in the logs
# and their individual log levels.
# Note that the actual logging level applied is the conjunction of the global logging level and the
# logging levels specified here for each namespace.
[logging.pkg-ns]
"" = "WARNING"
"aiotools" = "INFO"
"aiohttp" = "INFO"
"ai.backend" = "INFO"

[debug]
enabled = false

# vim: ft=toml

[otel]
# Whether to enable OpenTelemetry for tracing or logging.
# When enabled, traces or log will be collected and sent to the configured OTLP
# endpoint.
# Examples: True, False
enabled = false
# Log level for OpenTelemetry.
# Controls the verbosity of logs generated by OpenTelemetry.
# Common levels include 'debug', 'info', 'warn', 'error'.
# Examples: DEBUG, INFO, WARN, ERROR
log-level = "INFO"
# OTLP endpoint for sending traces.
# Should include the host and port of the OTLP receiver.
# Examples: localhost:4317, otel-collector:4317
endpoint = "localhost:4317"

[apollo-router]
# Endpoint of Apollo Router.
# This is used to route requests to the appropriate backend services.
# It should be a comma-separated list of URLs if multiple endpoints are used.
endpoint = "http://127.0.0.1:4000"
